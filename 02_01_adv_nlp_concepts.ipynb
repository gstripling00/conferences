{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPer3qro8lNXOtC1BQjGOux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gstripling00/conferences/blob/main/02_01_adv_nlp_concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKbVdoGepwn_"
      },
      "outputs": [],
      "source": [
        "##LIL - Advanced NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning Text Data#\n"
      ],
      "metadata": {
        "id": "Szuo9Wo1p4_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning text data in natural language processing (NLP) involves several preprocessing steps to prepare the data for analysis or model training. The specific processes may vary depending on the task and the characteristics of the data, but here are some common text cleaning processes:"
      ],
      "metadata": {
        "id": "pz7-yBJeqMV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Lowercasing**: Convert all text to lowercase.  Reason: Ensures consistency and reduces the complexity of the vocabulary.\n",
        "2.  **Removing HTML Tags and URLs**: Eliminate HTML tags and URLs from text. Reason: Removes irrelevant information and noise from web-based text.\n",
        "3.  **Handling Contractions**: Expand contractions (e.g., \"don't\" to \"do not\"). Reason: Ensures consistency and proper representation of words.\n",
        "\n",
        "4.  **Removing Punctuation**: Eliminate punctuation marks (e.g., commas, periods, exclamation points). Reason: Punctuation may not contribute significantly to certain NLP tasks, and removing them simplifies the text.\n",
        "\n",
        "5.  **Removing Special Characters**: Eliminate non-alphanumeric characters, such as symbols or special characters. Reason: Reduces noise and focuses on meaningful content.\n",
        "\n",
        "6.  **Tokenization**: Split text into individual words or tokens. Reason: Facilitates further analysis by breaking down text into its basic units.\n",
        "\n",
        "7.  **Handling Numerical Values**: Decide whether to keep or remove numerical values. Reason: Reduces noise and focuses on meaningful content.\n",
        "\n",
        "8.  **Removinig Stop Words**: Exclude common words (e.g., \"the,\" \"and,\" \"is\") that don't carry much information. Reason: Reduces dimensionality and focuses on more meaningful terms.\n",
        "\n",
        "9.    **Stemming and Lemmatization**: Reduce words to their base or root form. Reason: Consolidates variations of words to simplify analysis and improve feature representation.\n",
        "\n",
        "10.  **Spell Checking and Correction**: Correct spelling errors in the text. Reason: Improves the quality of the data and avoids misinterpretations.\n",
        "\n"
      ],
      "metadata": {
        "id": "3K0ICYCEs4uQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The order in which text cleaning processes are applied can depend on the specific requirements of your NLP task and the characteristics of your data.\n",
        "\n",
        "Keep in mind that the order can be adjusted based on the specific characteristics of your data and the goals of your NLP task. For instance, tokenization is often performed early in the process, and stemming/lemmatization can be done after stop word removal. The key is to consider the impact of each step on the quality and relevance of your text data for the intended analysis or model training."
      ],
      "metadata": {
        "id": "S73hCIaOzbE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0QZKqkwz2N6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tools to Clean Text Data#"
      ],
      "metadata": {
        "id": "KY5f04cmyVt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are several tools and libraries available in Python for cleaning and preprocessing text data in NLP. Here are some commonly used tools and applications:\n",
        "\n",
        "\n",
        "These tools can be used individually or in combination based on the specific requirements of your text preprocessing tasks. Additionally, popular deep learning frameworks like TensorFlow and PyTorch also provide tools for text preprocessing when working with neural network models."
      ],
      "metadata": {
        "id": "7fmkmR6G2Qcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK (Natural Language Toolkit)**:\n",
        "NLTK is a powerful library for working with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet.\n",
        "\n",
        "**spaCy**:\n",
        "spaCy is an open-source library for advanced natural language processing tasks. It provides pre-trained models for tokenization, part-of-speech tagging, named entity recognition, and more.\n",
        "\n",
        "**TextBlob**:\n",
        "TextBlob is a simple library for processing textual data. It provides tools for part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
        "\n",
        "**Scikit-learn**:\n",
        "Scikit-learn is a popular machine learning library, but it also provides utilities for text processing. It includes tools for feature extraction, text vectorization, and more.\n",
        "\n",
        "**Gensim**:\n",
        "Gensim is a library for topic modeling and document similarity analysis. It includes algorithms for word embeddings, document modeling, and more.\n",
        "\n",
        "**Beautiful Soup**:\n",
        "Beautiful Soup is a library for pulling data out of HTML and XML files. It is useful for web scraping and extracting text content from web pages.\n",
        "\n",
        "**RegEx (Regular Expressions)**:\n",
        "Regular expressions provide a powerful and flexible way to search, match, and manipulate text. They can be used in combination with Python's re module.\n",
        "\n",
        "**Spelling Correction Tools**:\n",
        "pyspellchecker, autocorrectVarious libraries are available for spell checking and correction in text data.."
      ],
      "metadata": {
        "id": "MjvHPa8s2W7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lowercasing: Convert all text to lowercase.\n",
        "Reason: Ensures consistency and reduces the complexity of the vocabulary."
      ],
      "metadata": {
        "id": "mG7KA-8TqRZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "maH6_WP1quKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}