{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODgWIc5bCbC2VNIKboHmV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gstripling00/conferences/blob/main/02_02_adv_nlp_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Natural Language Toolkit Setup\n",
        "\n",
        "NO need to install anything. Use Google's Colaboratory Jupyter Notebooks."
      ],
      "metadata": {
        "id": "D_wo1PpsrMUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tXG8euDKrEDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "-bt90qe5rCdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install all the data requirement for NLTK, first define the output directory and download it by running:"
      ],
      "metadata": {
        "id": "-kWgmOOYh8rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Specify the directory name\n",
        "directory_name = \"my_new_directory\"\n",
        "\n",
        "# Check if the directory already exists\n",
        "if not os.path.exists(directory_name):\n",
        "    # Create the directory\n",
        "    os.makedirs(directory_name)\n",
        "    print(f\"Directory '{directory_name}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Directory '{directory_name}' already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lfhMp0-hFIb",
        "outputId": "eea55c4a-3be2-4eb0-836c-2bccac6ed9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'my_new_directory' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the new path by right-clicking on the new directory folder and copying path.\n",
        "\n",
        "PATH = '/content/my_new_directory/nltk_data'\n",
        "nltk.data.path.append(PATH)\n"
      ],
      "metadata": {
        "id": "kDMikvM9hptC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(download_dir=PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzgiZfq5iE6s",
        "outputId": "96bca021-f9b9-4263-f570-a5c571d811e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> book\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'book'\n",
            "       | \n",
            "       | Downloading package abc to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package abc is already up-to-date!\n",
            "       | Downloading package brown to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package brown is already up-to-date!\n",
            "       | Downloading package chat80 to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package chat80 is already up-to-date!\n",
            "       | Downloading package cmudict to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package cmudict is already up-to-date!\n",
            "       | Downloading package conll2000 to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package conll2000 is already up-to-date!\n",
            "       | Downloading package conll2002 to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package conll2002 is already up-to-date!\n",
            "       | Downloading package dependency_treebank to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package dependency_treebank is already up-to-date!\n",
            "       | Downloading package genesis to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package genesis is already up-to-date!\n",
            "       | Downloading package gutenberg to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package gutenberg is already up-to-date!\n",
            "       | Downloading package ieer to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package ieer is already up-to-date!\n",
            "       | Downloading package inaugural to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package inaugural is already up-to-date!\n",
            "       | Downloading package movie_reviews to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package movie_reviews is already up-to-date!\n",
            "       | Downloading package nps_chat to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package nps_chat is already up-to-date!\n",
            "       | Downloading package names to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package names is already up-to-date!\n",
            "       | Downloading package ppattach to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package ppattach is already up-to-date!\n",
            "       | Downloading package reuters to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package reuters is already up-to-date!\n",
            "       | Downloading package senseval to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package senseval is already up-to-date!\n",
            "       | Downloading package state_union to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package state_union is already up-to-date!\n",
            "       | Downloading package stopwords to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package stopwords is already up-to-date!\n",
            "       | Downloading package swadesh to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package swadesh is already up-to-date!\n",
            "       | Downloading package timit to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package timit is already up-to-date!\n",
            "       | Downloading package treebank to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package treebank is already up-to-date!\n",
            "       | Downloading package toolbox to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package toolbox is already up-to-date!\n",
            "       | Downloading package udhr to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package udhr is already up-to-date!\n",
            "       | Downloading package udhr2 to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package udhr2 is already up-to-date!\n",
            "       | Downloading package unicode_samples to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package unicode_samples is already up-to-date!\n",
            "       | Downloading package webtext to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package webtext is already up-to-date!\n",
            "       | Downloading package wordnet to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package wordnet is already up-to-date!\n",
            "       | Downloading package wordnet_ic to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package wordnet_ic is already up-to-date!\n",
            "       | Downloading package words to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package words is already up-to-date!\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package maxent_treebank_pos_tagger is already up-to-date!\n",
            "       | Downloading package maxent_ne_chunker to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package maxent_ne_chunker is already up-to-date!\n",
            "       | Downloading package universal_tagset to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package universal_tagset is already up-to-date!\n",
            "       | Downloading package punkt to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package punkt is already up-to-date!\n",
            "       | Downloading package book_grammars to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package book_grammars is already up-to-date!\n",
            "       | Downloading package city_database to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package city_database is already up-to-date!\n",
            "       | Downloading package tagsets to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package tagsets is already up-to-date!\n",
            "       | Downloading package panlex_swadesh to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package panlex_swadesh is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /content/my_new_directory/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
            "       | \n",
            "     Done downloading collection book\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Did it work?\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords.words('english')[0:25] #show the first 25 words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6PI_4XSkEED",
        "outputId": "97ec972e-e48a-40d4-c5c7-428e4efeb7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}